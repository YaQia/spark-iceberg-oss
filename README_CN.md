# Spark + Iceberg + é˜¿é‡Œäº‘ OSS

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Spark](https://img.shields.io/badge/Spark-3.5.5-orange.svg)](https://spark.apache.org/)
[![Iceberg](https://img.shields.io/badge/Iceberg-1.8.1-blue.svg)](https://iceberg.apache.org/)

åŸºäºå®˜æ–¹ Apache Spark é•œåƒæ„å»ºçš„ç”Ÿäº§çº§ Docker é•œåƒï¼Œé›†æˆäº† Apache Iceberg å’Œé˜¿é‡Œäº‘ OSSï¼ˆå¯¹è±¡å­˜å‚¨æœåŠ¡ï¼‰æ”¯æŒã€‚æœ¬é¡¹ç›®ä¸ºåœ¨é˜¿é‡Œäº‘ OSS ä¸Šè¿è¡Œ Spark å·¥ä½œè´Ÿè½½å’Œä½¿ç”¨ Iceberg è¡¨æ ¼å¼æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

[English](README.md) | ç®€ä½“ä¸­æ–‡

## ğŸŒŸ ç‰¹æ€§

- **å®˜æ–¹ Apache Spark 3.5.5** åŸºç¡€é•œåƒï¼ŒåŒ…å« Scala 2.12ã€Java 11 å’Œ Python 3
- **æœ€æ–° Apache Iceberg 1.8.1** è¿è¡Œæ—¶ï¼Œæ”¯æŒç°ä»£åŒ–è¡¨æ ¼å¼åŠŸèƒ½
- **å®Œæ•´çš„é˜¿é‡Œäº‘ OSS é›†æˆ**ï¼ŒåŒ…å« hadoop-aliyun å’Œ aliyun-sdk-oss
- **Docker Compose** é…ç½®ï¼Œä¾¿äºæœ¬åœ°å¼€å‘å’Œæµ‹è¯•
- **å®Œæ•´ç¤ºä¾‹**ï¼ŒåŒ…æ‹¬ PySpark å’Œ Spark SQL ç¤ºä¾‹
- **ç”Ÿäº§å°±ç»ªçš„é…ç½®**ï¼Œéµå¾ªæœ€ä½³å®è·µ

## ğŸ“‹ å‰ç½®è¦æ±‚

- Docker (20.10+)
- Docker Compose (1.29+)
- é˜¿é‡Œäº‘ OSS è´¦æˆ·åŠè®¿é—®å¯†é’¥

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“

```bash
git clone https://github.com/YaQia/spark-iceberg-oss.git
cd spark-iceberg-oss
```

### 2. é…ç½® OSS å‡­è¯

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
cat > .env << EOF
OSS_ACCESS_KEY_ID=ä½ çš„è®¿é—®å¯†é’¥ID
OSS_ACCESS_KEY_SECRET=ä½ çš„è®¿é—®å¯†é’¥Secret
OSS_ENDPOINT=oss-cn-hangzhou.aliyuncs.com
OSS_BUCKET=ä½ çš„bucketåç§°
EOF
```

**é‡è¦æç¤ºï¼š** ç¡®ä¿åŒæ—¶æ›´æ–° `conf/spark-defaults.conf` æ–‡ä»¶ä¸­çš„ OSS å‡­è¯å’Œ bucket ä¿¡æ¯ã€‚

### 3. æ„å»º Docker é•œåƒ

```bash
docker build -t spark-iceberg-oss:latest .
```

### 4. å¯åŠ¨é›†ç¾¤

```bash
docker-compose up -d
```

è¿™å°†å¯åŠ¨ï¼š
- Spark Masterï¼ˆWeb UI: http://localhost:8080ï¼‰
- Spark Workerï¼ˆWeb UI: http://localhost:8081ï¼‰

### 5. è¿è¡Œç¤ºä¾‹

#### è‡ªåŠ¨å¿«é€Ÿå¯åŠ¨

```bash
# ä½¿ç”¨å¿«é€Ÿå¯åŠ¨è„šæœ¬
./quick-start.sh
```

#### PySpark ç¤ºä¾‹

```bash
# åœ¨è¿è¡Œçš„å®¹å™¨ä¸­æ‰§è¡Œ
docker exec -it spark-iceberg-master \
    spark-submit \
    --master spark://spark-master:7077 \
    /opt/spark/examples/iceberg_oss_example.py
```

#### Spark SQL ç¤ºä¾‹

```bash
# å¯åŠ¨ Spark SQL shell
docker exec -it spark-iceberg-master \
    spark-sql \
    --master spark://spark-master:7077
```

ç„¶åç²˜è´´ `examples/iceberg_sql_examples.sql` ä¸­çš„ SQL å‘½ä»¤ã€‚

## ğŸ“š æ¶æ„

### ç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Apache Spark 3.5.5                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Apache Iceberg 1.8.1 è¿è¡Œæ—¶                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         Hadoop é˜¿é‡Œäº‘ OSS è¿æ¥å™¨                â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚      é˜¿é‡Œäº‘ OSS SDK 3.18.5                â”‚  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   é˜¿é‡Œäº‘ OSS å­˜å‚¨      â”‚
                â”‚   oss://bucket/path   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ä¾èµ–é¡¹

| ç»„ä»¶ | ç‰ˆæœ¬ | ç”¨é€” |
|-----------|---------|---------|
| Apache Spark | 3.5.5 | åˆ†å¸ƒå¼è®¡ç®—å¼•æ“ |
| Apache Iceberg | 1.8.1 | å¤§è§„æ¨¡åˆ†ææ•°æ®é›†çš„è¡¨æ ¼å¼ |
| Hadoop Aliyun | 3.3.4 | OSS æ–‡ä»¶ç³»ç»Ÿå®ç° |
| Aliyun SDK OSS | 3.18.5 | é˜¿é‡Œäº‘ OSS å®¢æˆ·ç«¯åº“ |
| JDOM2 | 2.0.6.1 | XML å¤„ç†ï¼ˆOSS ä¾èµ–ï¼‰ |

## ğŸ”§ é…ç½®

### Spark é…ç½® (`conf/spark-defaults.conf`)

Iceberg å’Œ OSS çš„å…³é”®é…ç½®ï¼š

```properties
# Iceberg ç›®å½•
spark.sql.catalog.iceberg_catalog=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.iceberg_catalog.type=hadoop
spark.sql.catalog.iceberg_catalog.warehouse=oss://your-bucket/warehouse

# OSS è®¿é—®é…ç½®
spark.hadoop.fs.oss.endpoint=oss-cn-hangzhou.aliyuncs.com
spark.hadoop.fs.oss.accessKeyId=YOUR_ACCESS_KEY_ID
spark.hadoop.fs.oss.accessKeySecret=YOUR_ACCESS_KEY_SECRET
spark.hadoop.fs.oss.impl=org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem

# Iceberg æ‰©å±•
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
```

### ç¯å¢ƒå˜é‡

å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®ï¼š

- `OSS_ENDPOINT`: OSS ç«¯ç‚¹ URLï¼ˆé»˜è®¤ï¼šoss-cn-hangzhou.aliyuncs.comï¼‰
- `OSS_ACCESS_KEY_ID`: ä½ çš„é˜¿é‡Œäº‘è®¿é—®å¯†é’¥ ID
- `OSS_ACCESS_KEY_SECRET`: ä½ çš„é˜¿é‡Œäº‘è®¿é—®å¯†é’¥ Secret
- `OSS_BUCKET`: ç”¨äºæ•°æ®å­˜å‚¨çš„ OSS bucket åç§°

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»º Iceberg è¡¨

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("IcebergExample") \
    .getOrCreate()

# åˆ›å»ºæ•°æ®åº“
spark.sql("CREATE DATABASE IF NOT EXISTS mydb")

# åˆ›å»ºåˆ†åŒºè¡¨
spark.sql("""
    CREATE TABLE mydb.users (
        id BIGINT,
        name STRING,
        age INT,
        created_at TIMESTAMP
    ) USING iceberg
    PARTITIONED BY (days(created_at))
""")

# æ’å…¥æ•°æ®
spark.sql("""
    INSERT INTO mydb.users VALUES
    (1, 'Alice', 30, current_timestamp()),
    (2, 'Bob', 25, current_timestamp())
""")

# æŸ¥è¯¢æ•°æ®
spark.sql("SELECT * FROM mydb.users").show()
```

### æ—¶é—´æ—…è¡Œ

```sql
-- æŸ¥è¯¢å†å²æ•°æ®
SELECT * FROM mydb.users TIMESTAMP AS OF '2024-01-01 00:00:00';

-- é€šè¿‡å¿«ç…§ ID æŸ¥è¯¢
SELECT * FROM mydb.users VERSION AS OF 1234567890;

-- æŸ¥çœ‹è¡¨å†å²
SELECT * FROM mydb.users.history;
```

### Schema æ¼”åŒ–

```sql
-- æ·»åŠ åˆ—
ALTER TABLE mydb.users ADD COLUMN email STRING;

-- é‡å‘½ååˆ—
ALTER TABLE mydb.users RENAME COLUMN email TO contact_email;

-- åˆ é™¤åˆ—
ALTER TABLE mydb.users DROP COLUMN contact_email;
```

### MERGEï¼ˆUpsertï¼‰æ“ä½œ

```sql
MERGE INTO target_table t
USING source_table s
ON t.id = s.id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *;
```

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ Spark Submit

```bash
spark-submit \
    --master spark://spark-master:7077 \
    --conf spark.sql.catalog.iceberg_catalog=org.apache.iceberg.spark.SparkCatalog \
    --conf spark.sql.catalog.iceberg_catalog.warehouse=oss://your-bucket/warehouse \
    --conf spark.hadoop.fs.oss.endpoint=oss-cn-hangzhou.aliyuncs.com \
    --conf spark.hadoop.fs.oss.accessKeyId=YOUR_KEY \
    --conf spark.hadoop.fs.oss.accessKeySecret=YOUR_SECRET \
    your_application.py
```

### è¡¨ç»´æŠ¤

```sql
-- è¿‡æœŸæ—§å¿«ç…§
CALL iceberg_catalog.system.expire_snapshots(
    table => 'mydb.users',
    older_than => TIMESTAMP '2024-01-01 00:00:00',
    retain_last => 5
);

-- åˆ é™¤å­¤ç«‹æ–‡ä»¶
CALL iceberg_catalog.system.remove_orphan_files(
    table => 'mydb.users'
);

-- é‡å†™æ•°æ®æ–‡ä»¶ä»¥ä¼˜åŒ–è¡¨
CALL iceberg_catalog.system.rewrite_data_files(
    table => 'mydb.users'
);
```

### åœ¨ Kubernetes ä¸­ä½¿ç”¨

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: spark-driver
spec:
  containers:
  - name: spark
    image: spark-iceberg-oss:latest
    env:
    - name: OSS_ACCESS_KEY_ID
      valueFrom:
        secretKeyRef:
          name: oss-credentials
          key: access-key-id
    - name: OSS_ACCESS_KEY_SECRET
      valueFrom:
        secretKeyRef:
          name: oss-credentials
          key: access-key-secret
```

## ğŸ” æ•…éšœæ’é™¤

### OSS è¿æ¥é—®é¢˜

1. éªŒè¯ OSS ç«¯ç‚¹å¯¹äºä½ çš„åŒºåŸŸæ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥è®¿é—®å¯†é’¥ ID å’Œ Secret æ˜¯å¦æœ‰æ•ˆ
3. ç¡®ä¿ bucket å­˜åœ¨ä¸”ä½ æœ‰æƒé™è®¿é—®
4. æµ‹è¯•è¿æ¥ï¼š`hadoop fs -ls oss://your-bucket/`

### Iceberg è¡¨é—®é¢˜

1. æ£€æŸ¥ spark-defaults.conf ä¸­çš„ç›®å½•é…ç½®
2. éªŒè¯ warehouse è·¯å¾„åœ¨ OSS ä¸­æ˜¯å¦å¯è®¿é—®
3. æŸ¥çœ‹ Spark æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯

### æ€§èƒ½ä¼˜åŒ–

- ä½¿ç”¨é€‚å½“çš„åˆ†åŒºç­–ç•¥
- å¯ç”¨æ•°æ®æ–‡ä»¶å‹ç¼©ï¼ˆParquet é…åˆ Snappy/GZIPï¼‰
- å®šæœŸè¡¨ç»´æŠ¤ï¼ˆè¿‡æœŸå¿«ç…§ã€å‹ç¼©æ–‡ä»¶ï¼‰
- è°ƒä¼˜ Spark å†…å­˜å’Œæ‰§è¡Œå™¨è®¾ç½®

## ğŸ“¦ åŒ…å«å†…å®¹

```
spark-iceberg-oss/
â”œâ”€â”€ Dockerfile                          # Docker é•œåƒå®šä¹‰
â”œâ”€â”€ docker-compose.yml                  # å¤šå®¹å™¨é…ç½®
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ spark-defaults.conf            # Spark é…ç½®æ–‡ä»¶
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ iceberg_oss_example.py         # PySpark ç¤ºä¾‹
â”‚   â”œâ”€â”€ iceberg_sql_examples.sql       # SQL ç¤ºä¾‹
â”‚   â””â”€â”€ run_example.sh                 # ç¤ºä¾‹æ‰§è¡Œè„šæœ¬
â”œâ”€â”€ .env.template                       # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore                         # Git å¿½ç•¥è§„åˆ™
â”œâ”€â”€ quick-start.sh                     # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ LICENSE                            # Apache 2.0 è®¸å¯è¯
â”œâ”€â”€ README.md                          # è‹±æ–‡æ–‡æ¡£
â””â”€â”€ README_CN.md                       # ä¸­æ–‡æ–‡æ¡£
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤ Pull Requestã€‚

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤ä½ çš„ä¿®æ”¹ (`git commit -m 'æ·»åŠ ä¸€äº›å¾ˆæ£’çš„ç‰¹æ€§'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ä¸€ä¸ª Pull Request

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache License 2.0 è®¸å¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ”— å‚è€ƒèµ„æ–™

- [Apache Spark æ–‡æ¡£](https://spark.apache.org/docs/latest/)
- [Apache Iceberg æ–‡æ¡£](https://iceberg.apache.org/docs/latest/)
- [é˜¿é‡Œäº‘ OSS æ–‡æ¡£](https://help.aliyun.com/product/31815.html)
- [Hadoop Aliyun æ¨¡å—](https://hadoop.apache.org/docs/stable/hadoop-aliyun/tools/hadoop-aliyun/index.html)

## ğŸ“§ æ”¯æŒ

å¯¹äºé—®é¢˜å’Œç–‘é—®ï¼š
- åœ¨ GitHub ä¸Šå¼€å¯ä¸€ä¸ª issue
- æŸ¥çœ‹ç°æœ‰çš„ issues å’Œæ–‡æ¡£

## â­ Star å†å²

å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·è€ƒè™‘ç»™å®ƒä¸€ä¸ª starï¼

---

**ç”¨ â¤ï¸ ä¸º Apache Spark å’Œ Iceberg ç¤¾åŒºæ„å»º**
